* Week 1
** Intro Problem
   Given a text file as input. Generate a list of words sorted according to its
   frequency in the input file.

   - Literate Programming

   - Professor simple method
     #+BEGIN_SRC shell
       tr -cs a-zA-Z [\n]  |  sort  | uniq  -c  | sort -nr
     #+END_SRC

   - Parallelism on the Above Method
     In a four core matchine it is possible for true parallelism. However, sort
     can only output after finishing processing all its input.
** Language popularity
1. Java
2. C
3. C++
4. C#
5. Python
6. VBNET
7. js
8. Perl
9. assm
10. PHP

** Course description
   - Core of this course
     * Principles and *limitations* of programming models.

     * Notations for these models
       How to design, use and support for.

     * Methods to evaluate the strength and weakness of these notations in
       various contexts.

   - Current reading assignment: Ch 1-3, 5,7,9

   - Grading:
     * 40% final exam; open book + notes; closed computer

     * 20% midterm:

     * 40% HW: 6 - each 5%; 1 - 10%

     * Late penalty: same as 35L; due on 23:55 on the due date

   - Topics
     * Theory behind programming languages

     * Language design

     * Syntax

     * Semantics

     * Functions

     * Names

     * Types: descriptions of values

     * Control: Art of letting your program use CPU

     * Objects

     * Exceptions: Sort of control

     * Concurrency

     * Scripting: like shell, python

     * Exercises on Ocaml, Prolong, Java, Python

   - Some questions
     1. Why are there so many programming languages?
	Why cna't we just have one? There is a paper about "NExt 700 programming
        language".
	Why not only a broad-spectrum approach?

     2. Why software is so slow? (in lisp)
	Try C++ instead for fast memory access but loss reliability somehow.

** Reasons to prefer one language to another
- Popularity
- Support from compilers, debuggers, etc.
- Similarity to existing languages
- Simplicity
- Versatility: How widly can we apply this language
- Performance
  * CPU
  * Memory
  * IO (disk/flash)
  * Network
- Scalability: how well the language is for larger and larger program.
- Reliability
- Convenience: How easy to use? (i++ in C)

We have competing goals, like similarity is in contradiction with convenience.

- Orthoganality
  From mathematic concept, there are independent axis which means change in one
  axis does not impose changes on another axis. Once we have multiple features,
  people do not need to worry about some other features.

  Example: In C, a function can return any kind of types
  #+BEGIN_SRC C
    int f();
    char g();
    struct s h();
  #+END_SRC
  However, we cannot return an array (or a function). One argument is that copy
  is potentially expensive.
  Then what about a structure? We can have a structure that is really big and
  that works. 
  They want to emphasize that arr and pointer are the same thing.

  Consider you want to write a code return some type t defined
  elsewhere. However, that is not guaranteed feasible (what if that t is an
  array type or function type?). Therefore, C kind of lack of orthoganality.

- Safety(Important subset of reliability)
  Does not cause really bad consequence.

- Concurrency for multi-threaded program
- Exceptions handling
- Mutability (Successful language evolve)\
We want language that can change over time.
  
  Example: A language on 1971 run on PDP-11
  two int add
  16 KB RAM
  1.2 us memory

  Anyway, on this machine, memory access if considerably faster than
  cpu. Therefore, a language tuned for this machine has easy access to memory. 

  Nowadays, cpu speed is 100x faster than memory access.

Example: Varying number of args for function.
  In C there is some called Obj.
  Obj arr[7];
  arr[4] = ...
  arr[1] = ...
  Foo(7, arr); 
  What we really want: foo(x, yz, w, u, v) but we have to fill those variables
  in array. 

  We cannot realize this exactly but we can approach this as much as we can.
  #+BEGIN_SRC c
    #define ELTS(a) sizeof(a)/sizeof(*(a))
    #define CALLMANY(f, args) (f)(ELTS(args), args)

    #define CALLN(f, ...)  CALLMANY(f, (Obj[]{__VA_ARGS__}))

    Obj args[7];
    // Some Assignemtns
    //CALLMANY(Foo, args);
    CALLN(Foo, x, y,z ,u, v, a, b ,c);
  #+END_SRC

  #+BEGIN_SRC c
    #define IF if(
    #define THEN ){
    #define ELSE } else {
    #define FI }
  #+END_SRC

  These are examples of mutability. Can the program evolve with the changing
  hardware (outside world). Can it change according to the idea of the
  programmer.

** Syntax
   - whether a program is valid????
     #+BEGIN_SRC c
       int x = "abc"; // No syntax rule indicates that this is invalid
       int main(void) {return ""[1]; } // Stil, no syntax rule indicates that this is not valid.
     #+END_SRC
     Above programs are definitely wrong but not because of wrong syntax.

   - whether a program will compile????
     Consider the first example. It will not compile not because its syntax.

   - *A syntax is the form independent of meanings*
     In syntax we just care about its form. We do not care about what does it mean.

   - Syntax
     "Clolorless greed ideas sleep furiously." ===> Good syntax, nonsensee
     semantics.
     
   - Natural Language Syntax
      "Ireland has leoperd galore. "--P.Egger  ===> Bad syntax but meaning is
      clear

      In real life the meaning is important. However, in the world of
      programming, syntax is critical.

      "Time flies." 'Time' chould be none and verb, so does 'files'. This is the
      problem of ambiguity.

   - Programming language syntax: Reasons to prefer one over another
     * Inertia: Use syntax people have already get used to.
       a + b OR a b +

     * simple and regular
       Pick syntax that lets us say things easily.
       Some claim postfix notation is simpler and regular.
       In C, (a+b)*c. With postfix, a b + c * ==> No parens.

       The first reason prefers normal syntax

     * It's unambiguous
       #+BEGIN_SRC c
         a---b;
         // a-----b; does not work
         a--- --b;
       #+END_SRC
       Why a-----b does not work?
       Because the token analyzer (tokenizer) reads from left to right and it reads
       greedily. The above line of code is intepreted as (a)(--)(--)(-)(b).
       *Greedy means it is going to keep gluing characters together*
  - Tokenization
    comment: ??

  - Language without keyword: no reserved word
    Why we have language like this? ==> mutability? backward compatibility?
    Note that for C/C++ it is painful to improve the language.

Clear syntax is one where visualization skill "work"
Example
do {
   x/=10;
} while(x > 10);

do {
  x/=10
} until(x <= 10)

if( i > 0 && i < 1000) // Not what we want
if(0 < i && i < 1000)

* Week 2
** On Context free language
*** Some intro
- Sentence= finite sequence of tokens(terminal symbols)

- Token is from a set of finite elements.
  * Identifier: A special kind of token.
  * Some tokens have special information associated which is important for the
    language's semantics.
  * A sentence must be finite
  * Set of tokens must be finite: Important for analyzing of the language.

    Example: L = {a^nb^n | n >= 0}
             This language has infinite token set.
             This language does not scale well.

- Nonterminal
  Short for a (finite) sequence of tokens, than can be part of a sentence.

- Grammar
  * set of tokens(terminal symbols) and a finite set of nonterminal symbols.

  * Start symbol: a nonterminal symbols

  * finite set of rules

    Example: <nonterminal> -> finite sequence of symbols (either a terminal or
    nonterminal)

  * The compiler is going to figure out whether a sentence is a valid program language.

  * Recursive grammar: A symbol is both on the RHS and LHS

    Example: Internet RFS 5322 (request for comment)
    comtains a grammar for email headers.
    * Subject: <any sequence of chars, except newline>
      Grammar of subject content:
	    subject contents -> empty
	    subject contents -> subject_contents CHAR
	    (subject content -> CHAR subject_contents)

	    Different grammar can produce the same sentence.

    * MessageID: <xxx.xxx@xx.xx.xx>
      Grammar of MessageID:
      msg-id = "<" word *<"."word> "@" atom * ("." atom) ">"

      * Some meta-notation like "*" (not strict BNF but EBNF)
	EBNF just give us some convenience
	BNF <==> EBNF
	dotword -> <empty> | . word dotword vs. *<"."word>
	BNF is better for parser

    * Some other grammar
      atom = 1 * <any CHAR except special , SPACE and CR>  
      specials = ()<>@  
      word = atom | quotestring
      CTLS = \000 \037 \177
      quotestring = <"> *(qtext | quoted-pair) <">
      qtext = <any CHAR except " \ newline>
      quoted-pair = "\" CHAR 
	  
    * Possible trouble
      - Infinite long string
	Fixed by standard other than grammar

      - Control symbol in message

    * Use RegExpr: Turn a specification of a language to a program
      qp = '\\.'
      qt = '[^\"]'
      ps =

      Regular expression can be used to write grammar with meta-symbols and terminal symbols.
      However, regExpr cannot count.
      Note that recursion is not the limitation.
      Example: T -> abT is possible (tail-recursion)
               T -> aTb is not possible to convert (not tail-recursion)
               (tail-recursion rule)

- ISO Standard for EBNF: Decreasing in precedence
  * "token" or 'token'
  * [ option ]
  * { repetition }
  * (* comment *)
  * X* repetition of X
  * X-Y: X except for Y
  * X,Y: concatenation
  * X | Y: OR
  * X = expr;

- Define EBNF formmally
  syntax = syntax rule, {syntax rule};
  syntax rule = meta id, '=', defines list, ';' ;
  definitions list = defn, { '|', defns} ;
  Note: Define itself through itself

- Problems of Grammar
  * Large grammar is hard to understand
    * Syntax chart
  * Nonterminal used but not defined (bug in grammar)
    Or better described as "non-productive"
  * Nonterminal are defined but not used
    Or better described as "non-reachable"
    Cannot reach it from ths start symbol
    This applies recursively, consider the following with start symbol A
    W -> W A
    A -> /some other rules/ | <empty>

  * Ambiguity
    Has multiple way to parse the same input
    By making the program easy to parse, you may introduce ambiguity

    - Associativity
      E -> E+E
      E -> E-E
      E -> ID
      E -> (E)

      Has two ways to parse the sentence "a - b - c"

      - Problem: Is it possible to write a program to test the ambiguity of a
        grammar just by looking at the grammar itself?

        It is too hard. However, we still want to debug the grammar. 比如debug普通
        的程序很难，但是我们还是会去debug并且有所收获。Solve the general problem
        of ambiguity is hard, but we are looking for a practical partial solution.

      - General Idea: prohibit the part we do not want. Ambiguous grammar is too
      general. Consider the above grammar, is too general. Consider the second
      rule, the second E cannot be a plus/minus operation.

      - Change: result in a more complicated parse tree
      E -> T
      E -> E+E (This is stil a problem because E is allowed to recurse on both side)
      E -> E-T
      T -> ID
      T -> ( E )
 
      - Why we must have (a+b)+c?
      - Arithmetic overflow: Some order of the operation results in overflow
      - Floating point rounding problem
      - Side effects?
      - Unsigned arithmetic: Wrap around give different answer
	(a+b)+c if a and b are unsigned int but c is unsigned long

    - Precedence

      E -> T
      E -> E + T
      E -> E*T   ==> E -> F * T
                 ==> T -> F
      T -> ID    ==> F -> ID
      T -> ( E ) ==> F -> ( E )

      * Infix grammar has trouble of precedence

    - Another ambiguity in C
      * stmt: 
            ;
            break;
	    continue;
	    expr;
	    return expr; (no parens)
	    while (expr) stmt
	    do stmt while (expr); (we have no parens)

	* Some modification:
	  do stmt while expr; ==> This is not going to cause trouble)
          while expr stmt     ==> This may cause ambiguous because parser
          may combine expr and stmt together:
	  while i<1 *c / while i<1 -c;

	  The parens for expr in do-while is not going to solve ambiguity
          but it is still there because we want consistency.

      * Some other statement
	{ stmt or declaration list }
	for(expr; expr; expr;) stmt
	if (expr) stmt
	if (expr) stmt else stmt
	switch (expr) stmt
	    
	* Dangling "else" problem
	  fix: stmt: if (expr) stmt | stmt1 
	  stmt1 has everything except if (expr) stmt

  * Too much details 
    * because of ambiguity
      * Abstract syntax and concrete syntax
        Let the parser deal with known ambiguity issue directly instead of writing
        complex grammar rule.
    * because of attempts to cover too much
      IntE -> IntE + IntE | IntE * IntE | IntID| Inte
      StrE -> StrID | StrLiteral | StrE ^ StrE

      Note: The above is rarely done in real world language because there are
      infinite number of types. Generally grammar is only good at deal with
      syntax but not semantics.

- Expressions problems
  
  * user-defined operators (not the c++ way because we must pick the existing
    operator and give it new meaning)

    * Prolong: defining new operator
    :-op (700, xfx, [=, <=, >=,])
    :-op (500, yfx, [+,-])
    :-op (400, yfx, [*, /])
    :-op (200, xfy, [**])
    :-op (1200, xfy, [<--])

    - 500 is the precedence
    - y means same precedence is ok
    - x means same precedence is not ok

    - Note that ambiguity is not possible because "yfy" is not allowed. 

  * Side effect(especially in C/C++): a = f(x) + g(x);
    a = a++ -a++;
    We cannot determine the order of executing because compiler will optimize
    the code.

    Example of Professor:
    #+BEGIN_SRC c
      double stack[1000];
      double *top = &sstack[1000];
      #define PUSH(x) (*--top = (x))
      #define POP()   (*top++)
      switch(op) {
       case MULTI:
         PUSH( POP() * POP());
         break;
       }
    #+END_SRC
    *--top = (*top++) * (*top++);


* Week 3
** Functional programming
- Functional programming motivation
  - Clarity
  - performance

*** Clarity: 
- Take advantage of mathematic notation
  We want to build on mathematic traditions.
  - a + b = b + a
    May not true in C due to side effects
    (a+=10) + (a-=10)
  - E - E = 0
    what if E is getchar() which return different char each time.
  - i = i + 1 is definitely false mathematically

*** Performance
C or Java are designed for Von Neuman architecture(loading and store)

*** One success story (empty)

*** Function: What is a function
- CS: a chunk of code with a name
  This is how we think when we are implementing the function.

- Math: A mapping from a domain to a range
  This is how we think when we are using a function.
  
- Side Effect: Evaluation is no longer imposed by sequencing but only by function calls.
  #+BEGIN_SRC c
    a = f(x);
    b = g(y);
    c = h(z);
    e(a, b, c);
  #+END_SRC
  The above code might have hidden dependency so the sequential relationship
  must be as written.

  #+BEGIN_SRC c
    a = b + f(x) - b;
  #+END_SRC
  In C/C++ or Java, b cannot be eliminated.
  
- Referential transparency: Variables with the same name always have the same
  value.
    #+BEGIN_SRC ocaml
    let a = b + (f x) - b
  #+END_SRC

*** Higher Order Function (Functional forms in math)
- Functions that take function as argument
  "Build function on some other functions".
  * Summation operator
  * Integration operator
  * Function composition operator "o"

*** Ocaml
- Compile time type checking (like C/C++, Java)
  * Type inference
    Do not need to write all types down. The types are inferred from the
    context. 

- Garbage Collection
  No need to worry about storage management.

- Good support for higher order function

- Name and Types are really important in Ocaml

- Pattern matching
  #+BEGIN_SRC ocaml
  let cons (x,y) = x::y;;
  (* The above is equivalent to the following*)
       (fun a -> 
         match a with
         | (x,y) -> x::y)
  #+END_SRC

*** Functions
- Simple functions
  #+BEGIN_SRC ocaml
    (fun a -> a);;
    -: 'a -> 'a = <fun>

    (fun () -> ());;
    -: unit -> unit
#+END_SRC

- Higher order function
  #+BEGIN_SRC ocaml
    (fun x -> match x with
              | 0 -> (fun x -> -x)
              | _ -> (fun x -> x * 2));;
    -: int -> (int -> int) = <fun>
  #+END_SRC
  
  - Note that '->' is right associative
  - Function is left associative

- Recursion
  - Fib
    #+BEGIN_SRC ocaml
      let rec fib n =
      match n with
      | 0 -> 1
      | 1 -> 1
      | n -> fib(n-1) + fib(n-2)
    #+END_SRC

- Currying function: *All the functions are curried*
  - Max element in list
    #+BEGIN_SRC ocaml
      let rec maxlist =
      function 
      | (x::l) -> let m = maxlist l in if x < m then m else x
      | [] -> 0;;
    #+END_SRC

  - Reverse
    #+BEGIN_SRC ocaml
      let rec reverse= function
        | [] -> []
        | (x::l) -> (rev l) @ [x]
    #+END_SRC


** Reading
    1-9, 13, 15, 17
** HW
*** Theory
    1. Finite State Automata
    2. Push Down Automata = FSA + Stack
    3. Turing Machine: FSA dealing with infinite term.

*** Parsing a CFG
    1. Recursion
       Grammar rules are recursive.
    2. Concatenation
       Suppose S -> T U and we know how to build a matcher for T and U
       matcher = acceptor -> token list -> bool

    3. OR (disjunction)
       - lookahead
	 S -> a T b
	 S -> c U d
	 Check if it is a or c

	 However,
	 S -> a T b
	 S -> a U d
	 
	 But we can change it into the following form to use lookahead
	 S -> a S'
	 S' -> T b
	 S' -> U d

	 But if the "T" is "if then"  ???

       - Create a choice point while parsing
	 First parse a T b, if fail then parse a U b
	 BUt need memory to record information

       - Stack
	 Note that function call is build-in stack.

       - acceptor(token list -> bool)
         Takes a string of tokens and indicates correctness
	 #+BEGIN_SRC ocaml
           function | ")"::_ -> true | _ -> false
	 #+END_SRC

** Translation into machine code
   - Consider the following code
     #+BEGIN_SRC c
       int main()
       {
         return ! getchar();
       }
     #+END_SRC
     This piece of code will not compile because getchar() has not been
     declared. We need to include stdio.h

     #+BEGIN_SRC c
       #include <stdio.h>
       int mainn() { return !getchar();}
     #+END_SRC
     
   - Translation
     * Preprocessor: a kind of text expansion.
       #+BEGIN_SRC c
         extern int getchar(void);

         int main() {return !getchar();}
       #+END_SRC

     * Convert program text into sequence of tokens
       Each token is represented by a byte.

       *lexing*: extra information associated with the token. For example, the
       difference between "main" and any other identifier.

     * Parsing: Parse tree
     * Semantics analysis
       - Type checking
       - Scope checking
     * Intermediate code generation
       main:
            push &getchar
            push 0
            call 
            not
            ret
     * Code generation x86_64
       main:
            call getchar
	    tstl %eax, %eax
	    setn %eax, %eax
	    ret 

   - Unix design philosophy (software tools)
     Break a procoess into multiple independent pieces.
     Ensures independence but increase overhead.

   - Smalltallc Design Philosophy (IDE)
     

* Week 4

** Compiler vs. Intepreter


** Hybrid Approach: JVM

Foo.java -> java compiler -> Foo.class(bytecodes)
                              ||
			      \/
			      Java(intepret + profiler(for performance))
			      hotpot -> (another compiler) -> machine code
			      (this method is expensive so we only do it for "hotspot")

*** Profiling
- statistical: sample hw ip 100 times/s => make a histogram
      We can know the "hotspot" of our program

- Insert counting code (gcc -pg -fprofile -...)
      finer graine performance measrue

- Once we know the "hotspot" we translate it into machine code

- Cause nondeterministic performance

- Hard to debug on the lower level compiler
  * Nondeterministic
  * Generally we will never see the machine code??


** Linking

- Loading time dynamic linking (load code before main start)
  Library will be dynamically linked as part of initialization process.

- Running dynamic linking (use special function to call)
  Self modifying code
  * Pros: Flexibility
  * Cons: Library version conflict: some module need version 1 but some other need version 2
  * Cons: Worry about unstructed code
    Once we allow dynamic linking, our program may execute some suspicious code.

** Type
- Why we need type
  * Help us understand the code
    when we look at an id x, we know which operations are valid and which are
    not.  
  * Reliability/Redundancy
    #+BEGIN_SRC c
    string x;
    x = x + 1; // ???
    #+END_SRC
    Catch trivial mistakes early
  * Performance
    Type helps compiler generate better code

- Strongly Typed: All operations are type checked, you cannot escape
  C/C++ is not strongly typed.

- Primitive vs. Constructed types
  * Primitive types are built in while structure type are built by user.
  * array of C/C++ are constructed types

- What is type? Is it some data structure? How exposed is the implementation of
  a type?
  * Exposed Type
    User know details of the type: integral type

  * Abstract Type
    User only konw what operation can be done to that type
    check NaN
    #+BEGIN_SRC c
    bool isnanf(float x)
    { return x!=x; }
    bool isinfinityf()
    { return x!=0 && x == 2*x; }
    #+END_SRC
    
    - floating point
      * Abstract type 
      * Why we need small number?
	We need computation with small number
	#+BEGIN_SRC c
	if(x == y && x-y==0) // does this always true????
	#+END_SRC
	
*** Type equivalence: Structurally Equivalence and Name equivalence
    - C uses structural equivalence for typedef and name equivalence for struct
      type.

*** Subtype
    #+BEGIN_SRC pascal
    var a int,
    var b 1..127,
    #+END_SRC
    - Subtype in C
      * float and double
      * char* vs. char const* ???
	#+BEGIN_SRC c
	char *p;
	char const* c_p;
	c_p = p;
	// p = c_p
	#+END_SRC
	

** Polymorphism
   - Early polymorphism: Type Coersion & overloading
     int vs. unsigned int
     #+BEGIN_SRC c
     int i = random();
     if( i < -217473848)
     {
        printf("machine error");
     }
     #+END_SRC

     long vs. double

     multiple bugs
     double f(double, int);
     double f(int, double);
     f(3,5);

     Error: Semantically ambiguous

   - Parametric polymorphism
     * iterator
       Suppose a list of string, we want to remove the short ones
       
       s = iterator.next
       s.length < xxx
       s.remove()

       This code has some problems because collections might contian any object
       so first assigning an object to string may cause trouble.

       If we know we are working with list of string, we can do runtime cast.
       s = (string) iterator

       However, some language has static type checking.
       Also, runtime type check has may harm performance. Python has the
       "runtime type checking" problem.

       In java, we use java template to solve this problem.

                             c is a collection of string Collection<string>
                             
       for(iterator<string> = c.begin(), ...)
          String s = c.next()

       No runtime type check.
       
       ML, Java: Generic
       C++: templates

       Template method is different from java/ml method. In template, we
       instantiate the template with the actual type. We know what the type is
       at compile time. It is similiar to macros. We actually compitle the code
       n times if we have n template. The machine code is copied n times also.

       That not how generic work. In Java, we just compile the generic version
       once. It is going to think is that going to work with any type. We just
       have one copy of the machine code. 

       Generic wins?

       "sizeof T" with T some template type. The compiler can convert it into a
       constant. However, in generic, this is still a variable. We do not know
       the size.

       Another example
       T x,y;
       x = y;

       In template, we know what instruction to execute because the type is know
       at compile time. However, in generic we do not know which instruction to
       take. 

       However, Java or ML use some other method to make this efficient. Every
       object is a pointer. We will never see the actual object. The above
       assignment is just poiner assignment. (Java does not have "sizeof"
       operator either). That's how generic work. We do not need to know the
       exact type of our object. We are just dealling with pointers(references).
       
     * Subtypes and generic
       Soppose a list of string:
       List<string> ls = [                  ];
       List<Obejct> lo = ls;
       lo.add new Thread;
       String s = ls.get() // we want the most recently added object
       
       The problem is that although string is a subtype of object, list of
       string is not a subtype of list of object.

       #+BEGIN_SRC java
         void printALL(Collection<?> c) {
           for(object o: c) {
             Object o = c.next();
             System.out.println(o);
           }
         }

	 // Soppose we String has a subtype of BlueString
	 printAll(Collection<BlueString> cbs); // Does this work?
	                                       // No because collection of bluesring is not a subtype of collection os string
         void printAll<Collection(? extends String> o);
	 // Only accept types that extends string
       #+END_SRC
       #+BEGIN_SRC java
         public static void <T> convert( T[], Collection<T> c) {
             for(int i=0; i<a.len ; i++)
             c.add(a[i]);
         }

         /**
          ,** Suppose: BlueString[] a, Collection<String> c will not work on convert
          ,** because convert require two parameter to be the same type.
          ,**/

         public static void <T> convert( T[], Collection<? super T> c) {
             for(int i=0; i<a.len ; i++)
             c.add(a[i]);
         }

       #+END_SRC	 
       
     * Python & Subtype
       - Duck Typing: 
	 Never ask whether a type is the subtype of another type. Just check if
         it works.

** Java -- history
   - What we had
     workstations + servers + operation staff on a network = (Solaris written in
     C)
   - what they wanted: IoT
     * Reliability
     * size of program 
     * Flexibility(OOP)
     * architecture agnostic

   - First trial: C++
     C++ does provide flexibility but not other thing. For example, template
     increases program size.

   - Steal Smalltalk
     * OOP -> Flexibility
     * Bytecodes -> architecture agnostic
       Took program and translate it into machine independent bytecode. Then the
       interpreter will analyze the bytecode.
     * Runtime checking -> Reliability

   - Smalltalk bad ideas
     * Weird syntax
     * Program internally use secret bytecode
       For internet of thing, they need download bytecodes instead of machine
       code and let the hardware to intepret.
     
   - Oak ==> Java
     * 1995 Browser in Java
       HotJava and applets(java code compiled into bytecode)
     * And Browser Mosaic in C++
       which becomes IE and Mozilla
       Plugin technology which are dynamic linked machine code.
       To fix security issue, they later use javascript.
     * Java -> server worked well
            -> thread support
     

** Java Types
   - Primitive type
     byte, short, int, long, char, boolean, float, double
      8      16    32    64   16      1       32     64
                                           IEEE-754 fp

     In java, the those numbers are fixed for portable flexibility.
     In C, performance is more concerned. Machine are allowed to choose more
     suitable size.

     * Overflow??
       In C, overflow is undefined.
       In Java, overflow causes wrapping around ==> reliability.

   - References type
     Array.
     All objects are represented in pointers. You cannot see them but they're
     there.

     * Some thing valid in C++ but not in Java
       #+BEGIN_SRC c++
         int foo(int n) {
           char buf[512];

           return ...;
         }
       #+END_SRC

       Cannot allocate on the stack. Everything is on the heap.
       The size is dynamically chosen.
       Fixed after created.
       #+BEGIN_SRC java
         int foo(int n){
             char[] bof = new char[512];
             return xxx;
         }

         char[] foo(int n) {
             char[] bof = new char[512]; // Could be new char[n];
             return bof;
         }
       #+END_SRC 

** Java: Single Inheritance
   - Simple and elegant but not flexible
   - Use interfaces instead

* Week 5

** Abstract Class

*** Java Standard Library
1. Collection framwork
   Three interfaces
     (Copy)
     Serializable
     RandomAccess

   Collection of iterable which could be put into a for loop
     (Abstract collections) which implement collection
     List
       Abstract List
         Abstract Sequential list
	   LinkedList  ==> (implement) Queue CS
	   Array List CSR
	   vector (synchronized, thread-safe compared to array list) CSR
     Set 
       Sorted Set
       Abstract Set 
         Hash set (real class. can use the "new" keyword) CS
           LinkedHashSet
         TreSet CS

2. Object
   * Has constructor 
     so we can use "new" keyword for Object.
     Can be used as test case
     Placeholder

   * public boolean equal(Object arg);  == (reference equality)

   * public int hashCode();  default hashcode is some bits extracted from mem addr.
     For building hash table.
     We want the following to be true:
     If o1 == o2 then hashCode(o1) == hasCode(o2)
     Note that the reverse is not true.

   * public final Class<? extends Object> getClass(); 
     abstract (class) ==> subclass is mandatory
     final (class) ==> subclass is not allowed
     final (function) ==> cannot override it.
     Final allows inline and optimization ????

     Object o = ???
     Class c = o.getClass(); ==> May get "Thread"
     This is runtime type of o

     Reflection:
     Program tries to understand itself

     What is the point of getClass()?
     debug

     The "final" keyword does not allow overriding because you could write it in
     a way that it return a different class.

   * public String toString();
     For debug

   * protected void finalize(); can throw exception
     For garbage collector
     Why we need to override finalize method?
     A subclass overrides the finalize method to dispose of system resources or
     to perform other cleanup.

   * protected Object clone();
     
3. class Class
   * public final Class<? extends Object> getClass()
     

1. Thread
   Threads stay out of trouble via:
   * Synchronized
     int i;
     public synchronized int m() { i++; }
     this.lock() -> this.unlock()
   * Object.wait()
     1. remove all synchronized locks held by this thread
     2. Wait until the object beomes available

   * Object.notify()
     1. wakes up one thread 

* Week 6
** Data Synchronization
   * Exchange
     T1: v1 = x.exchange(v)
     T2: w1 = w.exchange(w)
     Only one thread will win

   * CountDownLatch
     Set up a latch such that all the threads are doing computation.

     Cycle Barrier
     what is cycle barrier

   * All the above method build on the wait() notify() method
     - Overhead: wait() and notify create bottleneck ????
     - Avoid synchronized keyword. We need safe memory access without locking.
     
   * Java Memory Model
     - Problems
       Optimizing compiler reordering instructions to make program run faster
       cache variables in registers

       Ex:
       o.x = o.y;
       o.x++;
       o.x = o.x;
       return o.z - o.y;

       Optimization: the compiler will eliminate all the code and create
       constant 1.

       EX: Reorder low level instruction
       movq x, rax
       addq $1, rax
       movq rax, z
       movq rax x

       The above instructions are not in the same order as the original code.

       So where is the problem? The optimization will make code run
       faster. However, in multithreading, this will going to cause problem:
       Inconsistency. ????

       Therefore, java memory model determines which optimization can be done.
       We want optimization as much as possible as long as they do not cause
       problem. 

       Casuality relationship

     - 九宫格
       * A normal load and normal store
         Could you exchange the order of normal load and store if the program is
         single threaded.

         o.x = 1;
         o.y = 2;
         This is the original order but the actual instruction can be in any
         order because this is single threaded.

         However, if 
         o.x = 1;
         o.y = o.x;

         This piece of code cannot be reordered.

       * B volatile(enter monitor) load and C volatile store (exit monitor)
	 volatile int n;

	 Tells the compiler not to optimize the code.
	 To solve the issue of "caching". Because we want each thread to look at
         the variable directly instead of looking at the cache.

	 Also, suppose
	 volatile int m,n;
	 int x,y;

	 l = o.x;
	 m = o.m;

	 The compiler can still reorder the above instructions (one is volatile
         and one is not).

	 o.m = 12;
	 o.x = 1;
     
       * Exception to the model: Constructor
	 Because constructor is normal store, may wind up with an object with
         garbage value in it.

	 The self pointer cannot be shared with other thread.  ????

	 Python mem model? ==> Global intepreter lock, bad peroformance
	 Java want high performance

** Name s & Binding
   - Binding: associate a name with a variable
   - Symbol table: a partial function from a name to a variable.
   - Example: int x = 12;
     1) What values are bound?
	Bound name "x" to 12
     2) When the binding happens
	Binding time occurs when the declaration is executed.
     3) We also bind the name to a type and the binding time is at compile
        time.
     4) Also bind the name to its memory address
	Could be function entry time if x is inside a function.

     Note the difference between declaration execution time and function entry
     time.
     struct x s = {0, &s}; The value of s binds later then its memory address.

     What about typedef
     typedef unsigned long sizet;
     Bind at ABI time. why????

   - Possible binding time
     1. execution time
     2. function entry time
     3. compile time
     4. ABI binding time
     5. Link time ==> Static or dynamic
	
   - Namespaces
     #+BEGIN_SRC c
       int f(void)
       {
         struct f {int f} f;    // struct tags
         enum f {zeros};        // enum tags
         struct g {int f } g;   // struct content
       #include <f>             // include file
       #define f g;             // preprocessor namespace
        f: goto f;              // label namespace because the label is only needed after goto
            
       }
     #+END_SRC
     - Label does not follow scope rule
     - Labeled namespace
       1. constructing a namespace
       2. give it a name

     - Visibility of identifier (Java as example)
       class
            int x;  (default visible to class and package)
            private int y; 
	    public int  z;
	    protected int w; (visible in class and subclass/visible in package)

       Class vs Package
     - Ocaml Namespace
     - Seperate Compilation
       double v double v????
** Logic Programming
   - Imperative: Focus on loops and assignment statement
   - Functional: Function definitions and calls
   - Logical: 
     Get rid of functions and (maybe calls) and only keeps recursions. 
     predicate, assertion and queries
     
   For Imperative  
   Algorithm = Logic + Control
   for(i=0;i<x;i++
   p(c);

   Logic ==> correctness
   Control ==>instructions to the machine
   
   For logical
   Program specifies logic while controls are specified independently
   The control in a logical program cannot affect the result you get, but only
   affect performance. Only the logic affects/defines the correctness.

   Cannot introduce bugs into our program through control.

   This is the idea of SEPARATION OF CONSERNS.

   Sorting Problem on C/C++ and Logic programming
   sort(L, S) :-    where L is the unsorted list while S is the sorted list.
   perm(L, S),
   sorted(S).

   sorted([]).
   sorted([H|T] :- 
   sorted(T),
   ltfeof(H, T).

   ltfef(H, []).
   ltfef(H, [H1|T1]) :-
   H =< H1.
     
   The anme ltfef bothers alot. When we feel it is hard to come out with a name,
   it is better to get rid of that method.

   sort(L,S)
   sorted([]).
   sorted([H]).
   sorted([X,Y]|L) :-
   X =< Y, sorted([Y|L]).

   perm([], []).
   perm([H|L], PHS ) :-
   append(P, [H|S], PHS),
   append(P, S, PS),
   perm(L, PS).

   append([], B, B).
   append([H|L], M, [H|LM]) :-
   append(L, M, LM).


** Prolog Syntax

   term -> atom 
           number integer and floating
	   variables (initially unbound variable) as you proceed the computation
                      the variable bound on success and unbound on failure.
	   structure(compound term) atom(termlist)

   Comparison
   atom and number are easy
   variable: bound variables are easy. Two unbound variable becomes one unbound
   variable under comparison.

   Syntax shorthand to reat syntax


** Prolog Program structure
   - fact
   - rules consequence :- antecedent
             term           termlist

   - Prolog is goal + control
     computation is query, which establishes a list of goal.
     computation is left-to-right
     depth first search

   - Example that the computation could go wrong
     The simplest possible predicate: true.

     repeat.
     repeat :- repeat.
     ?- repeat, write("foo"), nl, fail.

     loop :- loop.
     loop.

     Note that the logic is the same but the behavior/control is different.

     member(X, [X|L]).
     member(X, [_|L]) :- member(X, L).
     (append(_, [X|_], L).)


     reverse list
     
     reverse([],[]).
     reverse([X|L], R) :-
     reverse(L,R2),
     append(R2, [x], R).

     reva(L, A, L'A).
     reva([], A, A).
     reva([X|L], A, R) :-
     reva(L, [X|A], R).

     reverse(L,R) :- reva(L, [], R).

     
* Week 7
** Reading
Chapter 1 - 15, 17, 19, 20, 22

** is/2 ---- arithmetic
is(N, 2+2).
  * The second term must be /ground term/
    - term contains no logical variables
    - other wise what if 1234 is N*N?
      To make the machine code efficient
    - Note that in Ocaml, all variables are ground term.
    - As the result of an "is query", the variable is bound to the result of
        the expression

** Debugging?
   * trace

** Memory Management
   - Data structures in Prolog (terms, lists) are on the heap.
   - Another efficient implementation: On Stack
     Grow as you succeeds.
     Shrink as you fail.
     However, if a goal fails, all variables get unbound. 
     Typically, unbound variables are self pointers.

     The stack also contains a trail: a list of varaibles addresses that have
     been bounnd. When you fail, not only do you pop the term from the stack,
     you also pop the trail which allows you unbound the variables. Detail
     depends on the implementation. The trail itself could be a stack.

   - Stack management is fast.
   - Stack overflow?? 
     If a program that keeps succeeding, the stack is going to keep growing.
     The solutions is that they look the huge stack and look for objects to
     which cannot possibly be referred. This implementation is really a heap.
     Therefore, normally the program can think the stack as stack. However, if
     the stack grows too big, the problem of heap management comes. 
     *Efficient Prolog algorithm does not "succeed" everytime.*

** Unification
Given two terms, find a way to unify them such that they become equal. 
"Come with some way to make two terms equal."
Usually, the way is by binding logical variables.

Think of unification as bidirection pattern matching. What is this
"bidirection"????

*** Problem 
p(X,X).
?- p(Z, f(Z)).

Z = f(f(f(f(f(f(f(f(......
Z is an infinite term.

Zero.
Succ(E).

add(Zero, X, X) 
add(succ(X), Y, succ(XplusY)) :- add(X, Y, XplusY).
sub(XplusY, X, Y) :- add(X, Y, XplusY).

lt(X, succ(X)).
lt(X, succ(Y)) :- lt(X, Y).

?- lt(I, I).

=(X, X).
unify_with_occurs_check/2     same as '=' but fail on cycle

lt(X, succ(Y)) :- unify_with_occurs_check(X, Y).

The 'unify_with_occurs_check' is rarely used because
1. Most program don't create infinite terms.
2. It is slow due to cycle detecting. O(min) and O(max)????


Peano arithmetic 
(哥德尔不完备性定理)


** Cut!
p(X,Z) :- q(X, L), member(X, L), r(X, Z).
If the r(X, Z) is really expensive, and we have multiple same failing instance in the
list L. Then that same instance is going to fail three times on that expensive
predicate.

The first time X=a, r(X, Z) fails and then the program backtrack to member and
continues to find another X=a which will fail again.

*** Approx Not with Cut
not(G) :- G,!,fail.
not(_).

?- X = 3, not(X = 4).
X = 3.

?- not(X = 4), X=3.
false. because X is bounded to 4 and becomes true.

Cut break the logic: communitative operation becomes not communitative.

* Weak 8
** Scheme
   A subset of lisp, used for traditional AI (AI based on logic and arithmetic)
   Too slow for practical use ===> Academic

*** Basic Overview
    - Objects are dynamically allocated and never freed
      * Could be think that objects are represented by pointers
      * Could think Scheme as OOP
      * Always use 'new' to allocate
      * Never freed ==> 垃圾收集
      * Like Ocaml, Python (may be not java because Everything is object but in
        java primitive types are not objects
      * Unlike C/C++
    - types are latent not manifest
	* Latent: belongs to object (dynamic typeed, lkye python, unlike Ocaml,
          java, C/C++)
	* Manifest: belongs to expressions and identifier
    - Static scoping
	Like C/C++, Ocaml, Java, Python
	* Dynamic is scope is only clear at runtime
          * like lisp
	    int f(int x) { return g(s) }
	    int g(int n) { return n+x }
	    g has no x declared, so it looks at its caller (if still no, caller's
            caller)
	  * Like Bash shell
	    
	* Why Scheme do not use dynamic scoping?
	  * Performance

	  * Error checking: find such as misspell before the running
	* Why Dynamic scoping exists?
	  * Convenience and Flexibility: Only one instance can be used for all.
	* Similiar argument for static/dynamic type check
    - Call by value
	* Not like Prolog (call by unification)
    - BUilt-in objects of any built-in types
	* Lists, members, symbols...
	* Procedure(including continuation)
	  * Once created it immediately becomes part of teh future of your
            program.
	* Unlike most of other languages
    - Very simple syntax, with a straightforward representation of programs as
        data. 
	* Its trivial in Scheme to write a piece of data as program.
	* Unlike most of other language
	* It's trivial to write a Scheme program that read in other scheme
          program and check its syntax.
	* Can find some similarity with Prolog (take a "program" as input)
	* Need a lot of parens, but can write "metaprogram"
	  Write a program that alter other program and make them evolve.
    - Tail recursion optimization is required
	Can write recursive function in Scheme but you do not need to worry it
        exploding the stack
	* gcc with optimization flag does that
    - High level arithmetic
	* Integers are what we've learn in 3rd grade. No wrap around.
	* Never a integer overflow, but the size could exhaust memory.
	* Might be slower
	* Has exact fractions "1/3"
	  * Represent internally as two integer
	  * Know gcd algorithm to simplify
	* Floating point number
	
*** Syntax
    - Identifiers: a-zA-Z0-9+_.<,*/<=>:$%^&_~@
      * Cannot start with digit or -/+/*
	Some exception
      * By convention, identifier ending with question mark returns boolean
      * t->u is a conversion function
      * ; comment
      * improper list
        (a b . c): list does not end with nil
	Compare to (a b c) => (a b c nil)
	(a b . c ) => (a b c)
      * #f is the only way to represent false
      * vector
	
* Weak 9
** Scheme
Impelement thread** Use continuation to support thread
*** thread
*** lambda
*** define thread functions?
   - yield
   - thread-exit
   - fork
     (define (fork) (cdl/cc(lambda(k)(lwp(lamda()k #f)))))
*** similarities of C getcontext/setcontext and call/cc
*** Continuation passing style
   Continuation without doing call/cc
*** Continuation in Java
   - Not in C++ because
** Storage Management
*** Array allocation
    - double a[100]
      * With static keyword, the array is allocated once and never change.
      * Within a function, it is supposed to be allocated on stack.
      * In real world, compiler does not allocate 800*size(double), but allocate
        spaces for all the local variable because it is more efficient to do it
        in one instruction.
      * Conditional allocation?
	Allocate space that can hold the larger one.
      * double a[n]?
	Controversial feature.
	THe size is not known at compile time. This is going to slow down the
        code. 
	Need a stack base pointer and a stack pointer.
*** Nested Functions
    - Environment Pointer
      Points to the frame of the caller
*** Heap Management Issues
    - issues
      - Garbage Collector or explicit "free" operator
	Historically later is the option because 
        - Pros:
          it allows a fine grainer
          control of the memory and it is more efficient because the programmer
          knows exactly when the memory is not needed.
	- Con: 
          * Memory leaks. Programmer not always remember to free the memory.
	  * Use of dangling pointers. Things that are already deleted. Cause
            crash. 
	    In some machines, only copying the the dangling pointer will cause
            crash.
	    #+BEGIN_SRC c
              char *p = malloc(30);
              // ....
              //....

              free(p);
              char *q = p // crash in some machine
	    #+END_SRC
	  
	
      - If assume GC:  Finding roots and how to find pointers in objects
	GC have to figure out which part of the heap are in use and which part
        of the heap are where no body cares.
	THe problem is how to find the roots.
	- Root Finding
	  * The compilier and linker generate a tabled roots. This table will
            find all the stuff in static memory. The table will tells us which
            is roots.
	    This is a complicated table that maps ip values to sets of
            registers. Looks for movq etc.
	  * No tabls. Instead, the runtime guesses conservatively. (called
            conservative GC). If a word looks like a pointer ino the heap, then
            assume it is a pointer.
	    The downside is that the conservative guesses. In practive it does
            not leak much memory.
      - What you do with these information. The info will tell you where the
        object in use are.
	- Mark + Sweep
	  * Clear all mark bits
	  * Find all roots and traverse reachable objects, setting their mark
            bits.
	  * Find all objects whose mark bits are still zero. Then free them. 
	- Can freeze the app.
	  Can use GC in another thread. BUt this is complicated due to race
          condition.
	- Incremental GC (==> Real time GC)
      - Heap arena. Linear array of bytes
      - Basic assumption is that malloc is slow
	Private free list to avoid calling of malloc.
      - Alternatives to mark+sweep
	- Python: Reference count + markandsweep
	  * Reference counts. A count of the number of pointers to this object.
	    Cons: Pointer assignment becomes more expensive.
	          Cyclic data structures
            Pros: Free objects immediatly when it counts to zero.
	  * Python on JVM with Java GC
	- Generation based Copying Collector
	  - malloc(n)
	    heap pointer 左边有object右边是free，和heap limit pointer
	    希望mallochenkuai。要把hp和lp放进寄存器。
	    f=hp
	    hp+=n
	    if(hp>lp) then slowCode()
	    return r
	    希望malloc的机器指令少于10对于任何一直架构。

	    给object做年龄普查，把他们分成不同的generations。从老到年轻。
	    hp和lp是在最新的generation分类中的。
	    如果这样分类。那么对于面向对象语言有这么一个pattern可以利用，那就是
            新object总是会指向就得object。相反的情况比较少见。
	    假设hp一直在grow然后我们发现到了极限，那么垃圾更可能出现在刚刚增长的
            那些东西中间。

	    所以这个垃圾收集的想法就是，仅仅收集新生出来的垃圾。
	    对于过去很老的object指向新生object的情况，我们可以吧老的generation全
            设定为只读，如果有人尝试读取那个object，就会有pagefault，那我们只要
            把它设定成可读可写就好了。

	    Second idea: Copying
	    假设我们只找到了两个不是垃圾的object。我们把这些可用对象复制到一个新
            的“新生generation”跟类中。allocatd object被放在了一起。
	    这个对缓存的利用更好，因为互相引用的object很可能会被放在同一个缓存
            line中。
	    并且我们可以有一个非常快的malloc。因为我们只有一个大的freeblock。
	    并且，我们没有freelist。只要把正在使用的object移动到别处就好了。也就
            是说不需要在关心垃圾object。

	    麻烦的地方就是，如果有老的object指向新的object，我们需要relocate这些
            pointers。 
	    
	    有没有可能结合“保守GC”和上面说的结合起来呢？不可能因为我们需要重新调
            整旧pointer。

	    另外也有可能对于private freelist做出错误决定。
	  - 多线程
	    我们可以锁住heap。所以不同的线程就不能同时运行new了。
	    可以让每个线程都有自己的“新生heap”。

